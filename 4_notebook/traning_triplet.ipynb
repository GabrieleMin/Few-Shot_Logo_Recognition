{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Config:\n",
        "    # 1. SETUP\n",
        "    project_name = \"FewShot\"\n",
        "    \n",
        "    # Paths for saving results and checkpoints\n",
        "    logs_dir = \"./logs\"\n",
        "    checkpoints_dir = \"./checkpoints\"\n",
        "    \n",
        "    # Device configuration\n",
        "    if torch.backends.mps.is_available():\n",
        "     device = \"mps\"\n",
        "    elif torch.cuda.is_available():\n",
        "     device = \"cuda\"\n",
        "    else:\n",
        "     device = \"cpu\"\n",
        "    seed = 42  # For reproducibility\n",
        "\n",
        "    # 2. DATASET PATH\n",
        "    dataset_root = \"LogoDet-3K/LogoDet-3K-divided\"\n",
        "    csv_index_path = \"LogoDet-3K\"\n",
        "\n",
        "    # Split Ratios: 70% Train, 20% Validation \n",
        "    train_split_ratio = 0.7\n",
        "    val_split_ratio = 0.2\n",
        "\n",
        "    # 3. TRAINING HYPERPARAMETERS\n",
        "    epochs = 20\n",
        "    batch_size = 8\n",
        "    learning_rate = 1e-5\n",
        "\n",
        "    # 4. MODEL ARCHITECTURE\n",
        "    backbone = \"resnet50\" \n",
        "    pretrained = True     \n",
        "    embedding_dim = 128    \n",
        "\n",
        "    # TRAINED MODEL PATH\n",
        "    trained_model_path = \"\"\n",
        "\n",
        "    # Prediciton threadshold used to decide if two logos are the same during inference\n",
        "    prediciton_threashold = 0.5\n",
        " \n",
        "    \n",
        "   \n",
        "\n",
        "    freeze_layers = 0\n",
        "    # Transfer Learning Strategy\n",
        "    freeze_early_layers = True\n",
        "    # Unfreeze all layers after this specific epoch for fine-tuning\n",
        "    unfreeze_at_epoch = 5\n",
        "\n",
        "    # 5. LOSS FUNCTION\n",
        "    margin = 0.2           # Minimal distance between different logos \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    def tqdm(iterator, desc=\"\"): return iterator\n",
        "import glob\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "SEED = 101\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom Dataset for Triplet Learning (Anchor, Positive, Negative).\n",
        "\n",
        "Key operations:\n",
        "1. Efficient Indexing: Pre-computes a {label: [paths]} dictionary for fast positive/negative retrieval.\n",
        "2. Triplet Sampling:\n",
        "   - Anchor: Image at current index.\n",
        "   - Positive: Random different image from the same class (handles single-image classes).\n",
        "   - Negative: Random image from a different class.\n",
        "3. Robustness: Includes try-except block to return black fallback images if file loading fails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class DatasetTriplet(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "        # --- OTTIMIZZAZIONE ---\n",
        "        # Creiamo un dizionario {label: [lista_di_percorsi]}\n",
        "        # Questo serve per trovare velocemente i positivi e i negativi senza scorrere tutto ogni volta\n",
        "        self.label_to_images = {}\n",
        "        for img_path in image_paths:\n",
        "            # Assumiamo struttura: .../BrandName/img.jpg\n",
        "            # Adatta questo split se le tue cartelle sono diverse!\n",
        "            label = os.path.basename(os.path.dirname(img_path))\n",
        "            \n",
        "            if label not in self.label_to_images:\n",
        "                self.label_to_images[label] = []\n",
        "            self.label_to_images[label].append(img_path)\n",
        "            \n",
        "        self.labels = list(self.label_to_images.keys())\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # 1. ANCHOR (Immagine di partenza)\n",
        "        anchor_path = self.image_paths[index]\n",
        "        anchor_label = os.path.basename(os.path.dirname(anchor_path))\n",
        "        \n",
        "        # 2. POSITIVE (Stesso brand, immagine diversa)\n",
        "        potential_positives = self.label_to_images[anchor_label]\n",
        "        \n",
        "        # Se c'è solo un'immagine per quel brand (caso limite), usiamo la stessa\n",
        "        if len(potential_positives) > 1:\n",
        "            while True:\n",
        "                pos_path = random.choice(potential_positives)\n",
        "                if pos_path != anchor_path:\n",
        "                    break\n",
        "        else:\n",
        "            pos_path = anchor_path\n",
        "        \n",
        "        # 3. NEGATIVE (Brand diverso)\n",
        "        while True:\n",
        "            neg_label = random.choice(self.labels)\n",
        "            if neg_label != anchor_label:\n",
        "                break\n",
        "        neg_path = random.choice(self.label_to_images[neg_label])\n",
        "\n",
        "        # Caricamento immagini con gestione errori (se un file è corrotto non crasha tutto)\n",
        "        try:\n",
        "            anchor_img = Image.open(anchor_path).convert('RGB')\n",
        "            pos_img = Image.open(pos_path).convert('RGB')\n",
        "            neg_img = Image.open(neg_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Errore caricamento: {e}. Uso immagini nere di fallback.\")\n",
        "            anchor_img = Image.new('RGB', (224, 224))\n",
        "            pos_img = Image.new('RGB', (224, 224))\n",
        "            neg_img = Image.new('RGB', (224, 224))\n",
        "\n",
        "        if self.transform:\n",
        "            anchor_img = self.transform(anchor_img)\n",
        "            pos_img = self.transform(pos_img)\n",
        "            neg_img = self.transform(neg_img)\n",
        "\n",
        "        # Ritorna le 3 immagini + la label (utile per debug)\n",
        "        return anchor_img, pos_img, neg_img, anchor_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "ResNet50-based architecture modified for Metric Learning (generating embeddings).\n",
        "\n",
        "Key operations:\n",
        "1. Backbone Initialization: Loads a standard ResNet50 (optionally with ImageNet weights).\n",
        "2. Head Replacement: Swaps the original 1000-class classifier with a linear projection layer to output embeddings of size `embedding_dim`.\n",
        "3. Progressive Freezing: Implements a custom `freeze_numer_of_layer` method to selectively freeze backbone blocks (from shallow 'conv1' to deep 'layer4') for controlled fine-tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class LogoResNet50(nn.Module):\n",
        "    def __init__(self, embedding_dim=128, pretrained=True, num_of_freeze_layer=5, activation_fn=None):\n",
        "        super(LogoResNet50, self).__init__()\n",
        "        \n",
        "        # 1. Load Pre-trained Weights\n",
        "        # Initialize the model with weights pretrained on ImageNet for transfer learning\n",
        "        if pretrained:\n",
        "            weights = ResNet50_Weights.DEFAULT\n",
        "            self.model = models.resnet50(weights=weights)\n",
        "        else:\n",
        "            self.model = models.resnet50(weights=None)\n",
        "            \n",
        "        # 2. Modify the Head (Fully Connected Layer)\n",
        "        # We need to produce feature embeddings instead of class probabilities\n",
        "        input_features_fc = self.model.fc.in_features # Typically 2048 for ResNet50\n",
        "        \n",
        "        head_layers = []\n",
        "        # Project features to the desired embedding dimension (e.g., 128)\n",
        "        head_layers.append(nn.Linear(input_features_fc, embedding_dim))\n",
        "        \n",
        "        # Add an optional activation function if provided\n",
        "        if activation_fn is not None:\n",
        "            head_layers.append(activation_fn)\n",
        "        \n",
        "        # Replace the original classifier with our custom embedding head\n",
        "        self.model.fc = nn.Sequential(*head_layers)\n",
        "\n",
        "        # 3. Freezing Management\n",
        "        # Define the blocks here to access them in the freeze method.\n",
        "        # This structure allows progressive freezing/unfreezing strategies\n",
        "        self.blocks = [\n",
        "            ['conv1', 'bn1'],   # Level 1\n",
        "            ['layer1'],         # Level 2\n",
        "            ['layer2'],         # Level 3\n",
        "            ['layer3'],         # Level 4\n",
        "            ['layer4'],         # Level 5: Entire backbone frozen\n",
        "        ]\n",
        "\n",
        "        # Apply the initial freezing configuration\n",
        "        self.freeze_numer_of_layer(num_of_freeze_layer)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "    def freeze_numer_of_layer(self, num_of_freeze_layer):\n",
        "        \"\"\"\n",
        "        Manages layer freezing for transfer learning strategies.\n",
        "        \n",
        "        Args:\n",
        "            num_of_freeze_layer (int):\n",
        "              0   -> All layers unlocked (Full Fine-Tuning)\n",
        "              1-5 -> Progressively freezes the backbone layers from shallow to deep\n",
        "        \"\"\"\n",
        "        \n",
        "        # STEP 1: RESET. Unfreeze everything (requires_grad = True).\n",
        "        # This ensures we start from a clean state before applying new constraints.\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # If num is 0, exit immediately (Full Fine-Tuning mode)\n",
        "        if num_of_freeze_layer == 0:\n",
        "            print(\"Configuration: Full Fine-Tuning (All layers are trainable)\")\n",
        "            return\n",
        "        \n",
        "        # Safety check to avoid index out of bounds\n",
        "        limit = min(num_of_freeze_layer, len(self.blocks))\n",
        "        \n",
        "        frozen_list = []\n",
        "\n",
        "        # STEP 2: Progressively freeze the requested blocks\n",
        "        for i in range(limit):\n",
        "            current_blocks = self.blocks[i]\n",
        "            for block_name in current_blocks:\n",
        "                # Retrieve the layer by name\n",
        "                layer = getattr(self.model, block_name)\n",
        "                \n",
        "                # Freeze parameters for this specific block\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "                \n",
        "                frozen_list.append(block_name)\n",
        "\n",
        "        print(f\"Freezing Level {limit}. Frozen blocks: {frozen_list}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splits the dataset into training and validation sets at the brand level, ensuring no class overlap.\n",
        "\n",
        "Key operations:\n",
        "1. Brand Separation: Divides brand folders into train/val subsets based on `val_split` using a fixed seed to ensure reproducibility.\n",
        "2. Adaptive Downsampling: If `total_set_size` is enforced, calculates the quota of images per brand. If this falls below `min_images_per_brand`, it reduces the number of participating brands to ensure the remaining ones meet the minimum image count.\n",
        "3. Image Collection: Randomly samples the calculated number of images for each selected brand, or retrieves all images if no total size limit is set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getTrainValPaths(root_dir, val_split, total_set_size=None, min_images_per_brand=2):\n",
        "    train_val_path = os.path.join(root_dir, 'train_val')\n",
        "    train_val_brands = []\n",
        "\n",
        "    # Collect brand folders\n",
        "    if not os.path.exists(train_val_path):\n",
        "        print(f\"Warning: {train_val_path} not found.\")\n",
        "        return [], []\n",
        "\n",
        "    for category in os.listdir(train_val_path):\n",
        "        cat_path = os.path.join(train_val_path, category)\n",
        "        if os.path.isdir(cat_path):\n",
        "            for brand in os.listdir(cat_path):\n",
        "                brand_full_path = os.path.join(cat_path, brand)\n",
        "                if os.path.isdir(brand_full_path):\n",
        "                    train_val_brands.append(brand_full_path)\n",
        "\n",
        "    # Split brands into Train and Val\n",
        "    val_size = int(len(train_val_brands) * val_split)\n",
        "    train_size = len(train_val_brands) - val_size\n",
        "    generator = torch.Generator().manual_seed(Config.seed)\n",
        "    train_subset, val_subset = random_split(train_val_brands, [train_size, val_size], generator=generator)\n",
        "    \n",
        "    train_brand_list = [train_val_brands[i] for i in train_subset.indices]\n",
        "    val_brand_list = [train_val_brands[i] for i in val_subset.indices]\n",
        "\n",
        "    train_data_list = []\n",
        "    val_data_list = []\n",
        "\n",
        "    # Sampling Logic\n",
        "    if total_set_size is not None:\n",
        "        images_per_brand = round(total_set_size / len(train_val_brands))\n",
        "        \n",
        "        if images_per_brand < min_images_per_brand:\n",
        "            print(f\"Not enough images per brand ({images_per_brand}), downscaling brand sets to ensure {min_images_per_brand} images/brand.\")\n",
        "            \n",
        "            # Calculate how many brands we can actually afford\n",
        "            new_total_brand_count = round(total_set_size / min_images_per_brand)\n",
        "            new_val_size = round(new_total_brand_count * val_split)\n",
        "            new_train_size = new_total_brand_count - new_val_size\n",
        "\n",
        "            train_brand_list = random.sample(train_brand_list, min(len(train_brand_list), new_train_size))\n",
        "            val_brand_list = random.sample(val_brand_list, min(len(val_brand_list), new_val_size))\n",
        "            images_per_brand = min_images_per_brand\n",
        "\n",
        "        for brand in train_brand_list:\n",
        "            imgs = glob.glob(os.path.join(brand, '*.jpg'))\n",
        "\n",
        "            if len(imgs) < min_images_per_brand:\n",
        "                print(f\"images are less than {min_images_per_brand} for this brand: {brand} in the TRAIN set\")\n",
        "\n",
        "            train_data_list.extend(random.sample(imgs, min(images_per_brand, len(imgs))))\n",
        "            \n",
        "        for brand in val_brand_list:\n",
        "            imgs = glob.glob(os.path.join(brand, '*.jpg'))\n",
        "\n",
        "            if len(imgs) < min_images_per_brand:\n",
        "                print(f\"images are less than {min_images_per_brand} for this brand: {brand} in the VALIDATION set\")\n",
        "            \n",
        "            val_data_list.extend(random.sample(imgs, min(images_per_brand, len(imgs))))\n",
        "    else:\n",
        "        for brand in train_brand_list:\n",
        "            train_data_list.extend(glob.glob(os.path.join(brand, '*.jpg')))\n",
        "        for brand in val_brand_list:\n",
        "            val_data_list.extend(glob.glob(os.path.join(brand, '*.jpg')))\n",
        "\n",
        "    return train_data_list, val_data_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training script for a Triplet Network (Anchor, Positive, Negative).\n",
        "\n",
        "Key operations:\n",
        "1. Data Pipeline: \n",
        "   - Splits data into train/val and applies heavy augmentation (ColorJitter, Flip) to training data.\n",
        "   - Initializes `DatasetTriplet` which yields triplets of images.\n",
        "2. Model Setup: Initializes `LogoResNet50` on the specified device.\n",
        "3. Optimization:\n",
        "   - Loss: Uses `TripletMarginLoss` (margin=1.0) to ensure the Anchor is closer to the Positive than the Negative by at least the margin.\n",
        "   - Optimizer: Adam with a low learning rate (1e-5).\n",
        "4. Training Loop: Feeds triplets into the network to generate three embeddings, calculates loss, and updates weights.\n",
        "5. Monitoring: Evaluates on the validation set and saves the 'best' model (lowest validation loss) and periodic checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_triplet():\n",
        " \n",
        "    save_dir = os.path.join(\"checkpoints\", \"triplet_run\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    device = torch.device(Config.device)\n",
        "    \n",
        "    # 1. Dataset e Dataloader\n",
        "\n",
        "    train_files, val_files = getTrainValPaths(\n",
        "        Config.dataset_root, \n",
        "        val_split=Config.val_split_ratio,\n",
        "        min_images_per_brand=2\n",
        "    )\n",
        "\n",
        "    # Transformations\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = DatasetTriplet(train_files, transform=train_transform)\n",
        "    val_dataset = DatasetTriplet(val_files, transform=val_transform)\n",
        "\n",
        "    # Dataloader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # 2. Model\n",
        "    print(\"Model Initialization (Triplet)...\")\n",
        "    # Using Freeze=0 \n",
        "    model = LogoResNet50(embedding_dim=Config.embedding_dim, pretrained=Config.pretrained, num_of_freeze_layer=Config.freeze_layers) \n",
        "    model = model.to(device)\n",
        "\n",
        "    # 3. Loss e Optimizer\n",
        "    # Margin 1.0\n",
        "    criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "    \n",
        "    # Optimizer \n",
        "    # Using 0.00001 (1e-5) \n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00001)\n",
        "    # 4. Training Loop\n",
        "    best_val_loss = float('inf')\n",
        "    num_epochs = 10\n",
        "    \n",
        "    print(f\"Starting training Triplet for {num_epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        # Progress bar\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        \n",
        "        # The dataset returns: anchor, positive, negative, label\n",
        "        for anchor, positive, negative, _ in pbar:\n",
        "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass triplo\n",
        "            out_a = model(anchor)\n",
        "            out_p = model(positive)\n",
        "            out_n = model(negative)\n",
        "            \n",
        "            # Calculate Loss\n",
        "            loss = criterion(out_a, out_p, out_n)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # --- VALIDATION ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for anchor, positive, negative, _ in val_loader:\n",
        "                anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "                out_a = model(anchor)\n",
        "                out_p = model(positive)\n",
        "                out_n = model(negative)\n",
        "                loss = criterion(out_a, out_p, out_n)\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        print(f\"VALIDATION Epoch {epoch+1}: Loss = {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Saving checkpoint\n",
        "        checkpoint_path = os.path.join(save_dir, f\"model_epoch_{epoch+1}.pth\")\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        \n",
        "        # Saving Best Model \n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), os.path.join(save_dir, \"best_model_triplet.pth\"))\n",
        "            print(\"New Best Triplet Model Saved!\")\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_triplet()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
