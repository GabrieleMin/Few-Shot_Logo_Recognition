{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Deep Metric Learning Training Pipeline**\n",
        "Overview: This notebook implements a comprehensive Deep Metric Learning pipeline specifically designed for Logo Recognition. The pipeline covers every stage of the process, including data preparation, model architecture definition, loss function implementation, and a robust training loop equipped with logging and checkpointing mechanisms."
      ],
      "metadata": {
        "id": "qs6umlZq-w7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuration System Analysis (Config)**\n",
        "It separates data paths and hyperparameters from the execution logic, ensuring that the experiment is both reproducible and portable across different environments.\n",
        "1. Environment & Path Management\n",
        "This section handles the setup of the working environment to ensure smooth execution.\n",
        "* WORK_DIR: The root directory of the project.\n",
        "* dataset_root: The source location of the image dataset.\n",
        "* checkpoints_base_dir: The destination folder where model weights (.pth files) and training logs are saved.\n",
        "* device: Automatically detects and assigns hardware acceleration (cuda for GPU or cpu).\n",
        "* seed: A fixed integer (set to 42) to enforce reproducibility in data splits and weight initialization.\n",
        "2. Model Architecture\n",
        "Defines the neural network structure without modifying the model class directly.\n",
        "* backbone: The pre-trained network architecture used as the feature extractor (set to 'resnet50').\n",
        "* embedding_dim: The dimension of the output vector (set to 128). This defines the coordinates of the geometric space where images are mapped.\n",
        "* freeze_layers: An integer determining how many initial layers are locked to preserve pre-trained features (0 indicates Full Fine-tuning).\n",
        "3. Training Strategy\n",
        "Contains the general parameters governing the learning cycle.\n",
        "* loss_type: The master switch (options: 'triplet', 'euclidean', 'cosine'). This determines which Dataset class is loaded and which Loss function is instantiated.\n",
        "* epochs: The total number of training iterations over the dataset.\n",
        "* split_ratios: The percentages used for partitioning data into Training, Validation, and Test sets.\n",
        "4. Hyperparameter Dictionary (HYPERPARAMS)\n",
        "A nested dictionary containing optimized configuration recipes tailored for each specific loss function. This allows for context-aware parameter loading.\n",
        "* Triplet / Euclidean Loss: Uses margin=1.0. These loss functions work on absolute Euclidean distances.\n",
        "* Cosine Loss: Uses margin=0.2. This works on normalized angular similarities (ranging from -1 to 1).\n",
        "* Optimizer: Uses Adam with a conservative learning rate (1e-5) to preserve the quality of the pre-trained features.\n"
      ],
      "metadata": {
        "id": "DRQRkyWl_Jhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**"
      ],
      "metadata": {
        "id": "RScl_tLAClpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "\n",
        "zip_path = '/content/LogoDet-3K.zip'\n",
        "extract_path = '/content/LogoDet-3K'\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    if os.path.exists(zip_path):\n",
        "\n",
        "        !unzip -q -o {zip_path} -d /content/\n",
        "        print(f\"Dataset in: {extract_path}\")\n",
        "    else:\n",
        "        print(f\"ERROR: File {zip_path} not found\")\n",
        "\n",
        "else:\n",
        "    print(\"Dataset found.\")"
      ],
      "metadata": {
        "id": "iJFgs8erCn39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757101cb-bfba-4a4c-d27d-065225f1823a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6eqzOQ1-RuM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Config:\n",
        "    loss_type = \"triplet\"\n",
        "\n",
        "    WORK_DIR = \"/content\"\n",
        "    dataset_root = \"/content/LogoDet-3K/LogoDet-3K\"\n",
        "\n",
        "    checkpoints_base_dir = os.path.join(WORK_DIR, \"runs\")\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    seed = 42\n",
        "\n",
        "    # Dataset Split\n",
        "    train_split_ratio = 0.7\n",
        "    val_split_ratio = 0.2\n",
        "\n",
        "    # Training Params\n",
        "    epochs = 20\n",
        "    backbone = \"resnet50\"\n",
        "    pretrained = True\n",
        "    embedding_dim = 128\n",
        "\n",
        "    freeze_layers = 0\n",
        "    freeze_early_layers = True\n",
        "    unfreeze_at_epoch = 5\n",
        "\n",
        "    HYPERPARAMS = {\n",
        "        \"euclidean\": {\n",
        "            \"batch_size\": 32,\n",
        "            \"margin\": 1.0,\n",
        "            \"learning_rate\": 1e-5,\n",
        "            \"folder_name\": \"contrastive_euclidean\",\n",
        "            \"description\": \"Contrastive Loss\"\n",
        "        },\n",
        "        \"cosine\": {\n",
        "            \"batch_size\": 32,\n",
        "            \"margin\": 0.2,\n",
        "            \"learning_rate\": 1e-5,\n",
        "            \"folder_name\": \"contrastive_cosine\",\n",
        "            \"description\": \"Contrastive Loss\"\n",
        "        },\n",
        "        \"triplet\": {\n",
        "            \"batch_size\": 32,\n",
        "            \"margin\": 1.0,\n",
        "            \"learning_rate\": 1e-5,\n",
        "            \"folder_name\": \"triplet_loss\",\n",
        "            \"description\": \"Triplet Loss\"\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading and Processing logic**\n",
        "\n",
        "It defines how images are loaded, paired, or grouped into triplets to train a neural network using PyTorch.\n",
        "\n",
        "Key components:\n",
        "\n",
        "1. DatasetTriplet Class\n",
        "\n",
        "      This class is designed for training with Triplet Loss.\n",
        "\n",
        "      Goal: To provide the model with three images at once:\n",
        "\n",
        "      Anchor: The reference image.\n",
        "\n",
        "      Positive: A different image of the same brand.\n",
        "\n",
        "      Negative: An image of a different brand.\n",
        "\n",
        "      Mechanism:\n",
        "\n",
        "      It parses the file path to extract the label (Brand Name).\n",
        "\n",
        "      It maintains a dictionary (label_to_indices) to know which images belong to which brand.\n",
        "\n",
        "      In __getitem__, it randomly samples a Positive and a Negative to form a valid triplet.\n",
        "\n",
        "      Safety Features: It includes fallback logic (e.g., if a brand has only one image, the Positive becomes the Anchor itself; it retries up to 50 times to find a valid Negative).\n",
        "\n",
        "2. DatasetContrastive Class\n",
        "\n",
        "This class is designed for training with Contrastive Loss (Siamese Networks).\n",
        "\n",
        "Goal: To provide the model with a Pair of images and a binary label.\n",
        "\n",
        " Mechanism:\n",
        "\n",
        "  It selects a first image (img1).\n",
        "\n",
        "  It flips a coin (50% chance) to decide if the second image (img2) should be the Same Brand (Positive pair) or a Different Brand (Negative pair).\n",
        "\n",
        "  Output: Returns (img1, img2, label), where label is 1 for similar and 0 for different (or vice versa depending on loss implementation).\n",
        "\n",
        "3. getPathsSetsByBrand Function\n",
        "\n",
        "This is a crucial utility for Data Splitting.\n",
        "\n",
        "Unique Feature: Unlike standard splitters that shuffle all images, this function splits the dataset by Brand (Class), not by Image.\n",
        "\n",
        "Example: If \"Coca-Cola\" is in the Training set, all Coca-Cola images go to Training. The Validation set will contain completely unseen brands (e.g., \"Pepsi\").\n",
        "\n",
        "Purpose: This simulates an Open Set or Few-Shot learning scenario, testing if the model can generalize to recognize similarity rather than just memorizing specific brands.\n",
        "\n",
        "It splits the brands into Train, Validation, and Test sets based on the provided ratios (e.g., 0.7, 0.2, 0.1).\n",
        "\n",
        "4. Technical Details\n",
        "\n",
        "Reproducibility: It sets a fixed SEED = 101 for random and torch to ensure that data splits and pairings are consistent every time you run the code.\n",
        "\n",
        "Cross-Platform Compatibility: It uses .replace('\\\\', '/') to ensure file paths work correctly on both Windows and Linux/Colab.\n",
        "\n",
        "Robustness: Both dataset classes have try-except blocks in load_image to handle corrupted images or path errors gracefully (returning a black image instead of crashing)."
      ],
      "metadata": {
        "id": "3N8nRlT2_5eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "SEED = 101\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "\n",
        "class DatasetTriplet(Dataset):\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "        self.label_to_indices = defaultdict(list)\n",
        "        for idx, img_path in enumerate(self.file_list):\n",
        "            label = img_path.replace('\\\\', '/').split('/')[-2]\n",
        "            self.label_to_indices[label].append(idx)\n",
        "\n",
        "\n",
        "        self.labels = list(self.label_to_indices.keys())\n",
        "\n",
        "        print(f\"[DatasetTriplet] Unique brands found: {len(self.labels)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def load_image(self, image_path):\n",
        "        try:\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "        except:\n",
        "            img = Image.new('RGB', (224, 224))\n",
        "\n",
        "        if self.transform:\n",
        "            img_transformed = self.transform(img)\n",
        "        else:\n",
        "            img_transformed = transforms.ToTensor()(img)\n",
        "\n",
        "\n",
        "        return {\"image\": img_transformed}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_img_path = self.file_list[idx]\n",
        "        anchor_label = anchor_img_path.replace('\\\\', '/').split('/')[-2]\n",
        "\n",
        "        # 1. Anchor\n",
        "        anchor_dict = self.load_image(anchor_img_path)\n",
        "\n",
        "        # 2. Positive\n",
        "        positive_indices = [i for i in self.label_to_indices[anchor_label] if i != idx]\n",
        "        if len(positive_indices) > 0:\n",
        "            positive_idx = random.choice(positive_indices)\n",
        "            pos_path = self.file_list[positive_idx]\n",
        "        else:\n",
        "            pos_path = anchor_img_path\n",
        "        positive_dict = self.load_image(pos_path)\n",
        "\n",
        "        # 3. Negative\n",
        "        if len(self.labels) < 2:\n",
        "            neg_label = anchor_label\n",
        "        else:\n",
        "            attempts = 0\n",
        "            while True:\n",
        "                neg_label = random.choice(self.labels)\n",
        "                if neg_label != anchor_label:\n",
        "                    break\n",
        "                attempts += 1\n",
        "                if attempts > 50:\n",
        "                    neg_label = anchor_label\n",
        "                    break\n",
        "\n",
        "        neg_idx = random.choice(self.label_to_indices[neg_label])\n",
        "        neg_path = self.file_list[neg_idx]\n",
        "        negative_dict = self.load_image(neg_path)\n",
        "\n",
        "        return anchor_dict['image'], positive_dict['image'], negative_dict['image']\n",
        "\n",
        "\n",
        "class DatasetContrastive(Dataset):\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        self.label_to_indices = defaultdict(list)\n",
        "        for idx, img_path in enumerate(self.file_list):\n",
        "            label = img_path.replace('\\\\', '/').split('/')[-2]\n",
        "            self.label_to_indices[label].append(idx)\n",
        "\n",
        "\n",
        "        self.labels = list(self.label_to_indices.keys())\n",
        "\n",
        "    def __len__(self): return len(self.file_list)\n",
        "\n",
        "    def load_image(self, image_path):\n",
        "        try: img = Image.open(image_path).convert('RGB')\n",
        "        except: img = Image.new('RGB', (224, 224))\n",
        "        if self.transform: img = self.transform(img)\n",
        "        else: img = transforms.ToTensor()(img)\n",
        "        return {\"image\": img}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        label = img_path.replace('\\\\', '/').split('/')[-2]\n",
        "        img1 = self.load_image(img_path)\n",
        "\n",
        "        is_positive_pair = random.choice([0, 1])\n",
        "\n",
        "        if len(self.labels) < 2:\n",
        "            is_positive_pair = 1\n",
        "\n",
        "        if is_positive_pair:\n",
        "            pos_indices = [i for i in self.label_to_indices[label] if i != idx]\n",
        "            if len(pos_indices) > 0:\n",
        "                idx2 = random.choice(pos_indices)\n",
        "                path2 = self.file_list[idx2]\n",
        "            else:\n",
        "                path2 = img_path\n",
        "        else:\n",
        "            attempts = 0\n",
        "            while True:\n",
        "                neg_label = random.choice(self.labels)\n",
        "                if neg_label != label:\n",
        "                    break\n",
        "                attempts += 1\n",
        "                if attempts > 50:\n",
        "                    neg_label = label\n",
        "                    break\n",
        "            idx2 = random.choice(self.label_to_indices[neg_label])\n",
        "            path2 = self.file_list[idx2]\n",
        "\n",
        "        img2 = self.load_image(path2)\n",
        "        return img1, img2, torch.tensor(is_positive_pair, dtype=torch.float32)\n",
        "\n",
        "# ==========================================\n",
        "# UTILS\n",
        "# ==========================================\n",
        "class DatasetTest(Dataset):\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.file_list)\n",
        "    def load_image(self, image_path):\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return {\"image\": img, \"label\": -1}\n",
        "    def __getitem__(self, idx): return self.load_image(self.file_list[idx])\n",
        "\n",
        "def getPathsSetsByBrand(dir, val_split, test_split, total_set_size=None, min_images_per_brand=2):\n",
        "    brand_list = []\n",
        "    for category in os.listdir(dir):\n",
        "        category_path = os.path.join(dir, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            for brand in os.listdir(category_path):\n",
        "                brand_path = os.path.join(category_path, brand)\n",
        "                if os.path.isdir(brand_path):\n",
        "                    brand_list.append(brand_path)\n",
        "\n",
        "    if not brand_list: return [], [], []\n",
        "\n",
        "    test_size = int(len(brand_list) * test_split)\n",
        "    val_size = int(len(brand_list) * val_split)\n",
        "    train_size = len(brand_list) - test_size - val_size\n",
        "\n",
        "    generator = torch.Generator().manual_seed(SEED)\n",
        "    tr_sub, val_sub, te_sub = random_split(brand_list, [train_size, val_size, test_size], generator=generator)\n",
        "\n",
        "    train_brand_list = [brand_list[i] for i in tr_sub.indices]\n",
        "    val_brand_list   = [brand_list[i] for i in val_sub.indices]\n",
        "    test_brand_list  = [brand_list[i] for i in te_sub.indices]\n",
        "\n",
        "    def collect(brands, limit=None):\n",
        "        imgs = []\n",
        "        for b in brands:\n",
        "            f = glob.glob(os.path.join(b, '*.jpg'))\n",
        "            if f:\n",
        "                if limit: imgs.extend(random.sample(f, min(len(f), limit)))\n",
        "                else: imgs.extend(f)\n",
        "        return imgs\n",
        "\n",
        "    limit = None\n",
        "    if total_set_size:\n",
        "        limit = max(min_images_per_brand, int(total_set_size / len(brand_list)))\n",
        "\n",
        "    return collect(train_brand_list, limit), collect(val_brand_list, limit), collect(test_brand_list, limit)\n",
        "\n",
        "def show_contrastive_with_bboxes(img1, img2): pass"
      ],
      "metadata": {
        "id": "rcE9mUlCA3Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50-based architecture modified for Metric Learning (generating embeddings).\n",
        "\n",
        "Key operations:\n",
        "\n",
        "1.\tBackbone Initialization: Loads a standard ResNet50 (optionally with ImageNet weights).\n",
        "2.\tHead Replacement: Swaps the original 1000-class classifier with a linear projection layer to output embeddings of size embedding_dim.\n",
        "3.\tProgressive Freezing: Implements a custom freeze_numer_of_layer method to selectively freeze backbone blocks (from shallow 'conv1' to deep 'layer4') for controlled fine-tuning."
      ],
      "metadata": {
        "id": "uSFjRdVp_sTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogoResNet50(nn.Module):\n",
        "    def __init__(self, embedding_dim=128, pretrained=True, num_of_freeze_layer=5, activation_fn=None):\n",
        "        super(LogoResNet50, self).__init__()\n",
        "\n",
        "        # 1. Load Pre-trained Weights\n",
        "        # Initialize the model with weights pretrained on ImageNet for transfer learning\n",
        "        if pretrained:\n",
        "            weights = ResNet50_Weights.DEFAULT\n",
        "            self.model = models.resnet50(weights=weights)\n",
        "        else:\n",
        "            self.model = models.resnet50(weights=None)\n",
        "\n",
        "        # 2. Modify the Head (Fully Connected Layer)\n",
        "        # We need to produce feature embeddings instead of class probabilities\n",
        "        input_features_fc = self.model.fc.in_features # Typically 2048 for ResNet50\n",
        "\n",
        "        head_layers = []\n",
        "        # Project features to the desired embedding dimension (e.g., 128)\n",
        "        head_layers.append(nn.Linear(input_features_fc, embedding_dim))\n",
        "\n",
        "        # Add an optional activation function if provided\n",
        "        if activation_fn is not None:\n",
        "            head_layers.append(activation_fn)\n",
        "\n",
        "        # Replace the original classifier with our custom embedding head\n",
        "        self.model.fc = nn.Sequential(*head_layers)\n",
        "\n",
        "        # 3. Freezing Management\n",
        "        # Define the blocks here to access them in the freeze method.\n",
        "        # This structure allows progressive freezing/unfreezing strategies\n",
        "        self.blocks = [\n",
        "            ['conv1', 'bn1'],   # Level 1\n",
        "            ['layer1'],         # Level 2\n",
        "            ['layer2'],         # Level 3\n",
        "            ['layer3'],         # Level 4\n",
        "            ['layer4'],         # Level 5: Entire backbone frozen\n",
        "        ]\n",
        "\n",
        "        # Apply the initial freezing configuration\n",
        "        self.freeze_numer_of_layer(num_of_freeze_layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def freeze_numer_of_layer(self, num_of_freeze_layer):\n",
        "        \"\"\"\n",
        "        Manages layer freezing for transfer learning strategies.\n",
        "\n",
        "        Args:\n",
        "            num_of_freeze_layer (int):\n",
        "              0   -> All layers unlocked (Full Fine-Tuning)\n",
        "              1-5 -> Progressively freezes the backbone layers from shallow to deep\n",
        "        \"\"\"\n",
        "\n",
        "        # STEP 1: RESET. Unfreeze everything (requires_grad = True).\n",
        "        # This ensures we start from a clean state before applying new constraints.\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # If num is 0, exit immediately (Full Fine-Tuning mode)\n",
        "        if num_of_freeze_layer == 0:\n",
        "            print(\"Configuration: Full Fine-Tuning (All layers are trainable)\")\n",
        "            return\n",
        "\n",
        "        # Safety check to avoid index out of bounds\n",
        "        limit = min(num_of_freeze_layer, len(self.blocks))\n",
        "\n",
        "        frozen_list = []\n",
        "\n",
        "        # STEP 2: Progressively freeze the requested blocks\n",
        "        for i in range(limit):\n",
        "            current_blocks = self.blocks[i]\n",
        "            for block_name in current_blocks:\n",
        "                # Retrieve the layer by name\n",
        "                layer = getattr(self.model, block_name)\n",
        "\n",
        "                # Freeze parameters for this specific block\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "                frozen_list.append(block_name)\n",
        "\n",
        "        print(f\"Freezing Level {limit}. Frozen blocks: {frozen_list}\")"
      ],
      "metadata": {
        "id": "oCUWRNlW_0Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Function** definitions used to train the LogoResNet50 model. These classes define the mathematical rules that teach the neural network how to distinguish between similar and dissimilar logo images in a vector space.\n",
        "Here is a breakdown of the three classes defined in the script:\n",
        "1. ContrastiveLossEuclidean\n",
        "This class implements the classic Contrastive Loss based on Euclidean distance.\n",
        "* Function: It creates a \"Siamese\" objective. It pulls pairs of images belonging to the same class (Label 1) closer together and pushes pairs from different classes (Label 0) apart.\n",
        "* Mechanism:\n",
        "    * If images are Similar: It minimizes the squared Euclidean distance between their embeddings.\n",
        "    * If images are Different: It penalizes the model if the distance is smaller than the defined margin (default 2.0).\n",
        "2. ContrastiveLossCosine\n",
        "This class implements Cosine Embedding Loss.\n",
        "* Function: Instead of measuring the straight-line distance (Euclidean), this measures the angle between the two feature vectors. This is often more effective for high-dimensional spaces where the magnitude of the vector matters less than its direction.\n",
        "* Input Requirements: It expects labels where 1 represents similar pairs and -1 represents dissimilar pairs.\n",
        "3. TripletLoss\n",
        "This class implements the standard Triplet Margin Loss.\n",
        "* Function: It uses a three-part input structure rather than pairs:\n",
        "    * Anchor: The reference image.\n",
        "    * Positive: An image of the same class as the Anchor.\n",
        "    * Negative: An image of a different class.\n",
        "* Goal: It forces the distance between the Anchor and the Positive to be smaller than the distance between the Anchor and the Negative by at least the specified margin (default 1.0). This is generally considered more robust than Contrastive Loss for ranking tasks like logo retrieval.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mRUsiukq_jwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLossEuclidean(nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLossEuclidean, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        # Label 1 = Similar | Label 0 = Dissimilar\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n",
        "        loss_contrastive = torch.mean(\n",
        "            (label) * torch.pow(euclidean_distance, 2) +\n",
        "            (1-label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        )\n",
        "        return loss_contrastive\n",
        "\n",
        "class ContrastiveLossCosine(nn.Module):\n",
        "    def __init__(self, margin=0.2):\n",
        "        super(ContrastiveLossCosine, self).__init__()\n",
        "        self.loss_fn = nn.CosineEmbeddingLoss(margin=margin)\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        return self.loss_fn(output1, output2, label)\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Triplet Margin Loss Standard.\n",
        "    Input: Anchor, Positive, Negative.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.loss_fn = nn.TripletMarginLoss(margin=margin, p=2)\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        return self.loss_fn(anchor, positive, negative)"
      ],
      "metadata": {
        "id": "jaCoeoAn_c-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training script**\n",
        "It coordinates all core components—configuration, dataset handling, model architecture, and loss functions—to execute the full training workflow.\n",
        "The script:\n",
        "* Sets up the execution environment and imports all required custom and PyTorch modules.\n",
        "* Loads training settings from a configuration class and dynamically selects hyperparameters based on the chosen loss function (Triplet, Euclidean, or Cosine).\n",
        "* Splits the dataset into training and validation sets and applies data augmentation for better generalization.\n",
        "* Initializes a ResNet-50–based embedding model and the corresponding metric learning loss.\n",
        "* Runs the training and validation loop for multiple epochs, performing forward passes, loss computation, backpropagation, and optimization.\n",
        "* Saves model checkpoints, logs training history to a CSV file, and generates loss curve plots to monitor convergence.\n"
      ],
      "metadata": {
        "id": "7gzUkvO6A6CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plots(train_losses, val_losses, output_dir, title_suffix=\"\"):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.title(f\"Loss Curve {title_suffix}\")\n",
        "    plt.plot(train_losses, label=\"Train Loss\", color=\"blue\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\", color=\"red\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plot_path = os.path.join(output_dir, \"training_plot.png\")\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "# =========================================================================\n",
        "# MAIN\n",
        "# =========================================================================\n",
        "def main():\n",
        "    loss_type = Config.loss_type\n",
        "\n",
        "    if hasattr(Config, 'HYPERPARAMS'):\n",
        "        params = Config.HYPERPARAMS[loss_type]\n",
        "        BATCH_SIZE = params['batch_size']\n",
        "        MARGIN = params['margin']\n",
        "        LR = params['learning_rate']\n",
        "        SAVE_FOLDER = params['folder_name']\n",
        "    else:\n",
        "        BATCH_SIZE = 32\n",
        "        MARGIN = 1.0\n",
        "        LR = 1e-5\n",
        "        SAVE_FOLDER = f\"{loss_type}_run\"\n",
        "\n",
        "    device = torch.device(Config.device)\n",
        "    save_dir = os.path.join(Config.checkpoints_base_dir, SAVE_FOLDER)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(f\"\\n{'-'*50}\")\n",
        "    print(f\"STARTING TRAINING: {loss_type.upper()}\")\n",
        "    print(f\"Batch Size: {BATCH_SIZE} | Margin: {MARGIN} | LR: {LR}\")\n",
        "    print(f\"Output Folder: {save_dir}\")\n",
        "    print(f\"{'-'*50}\\n\")\n",
        "\n",
        "    # --- DATASET ---\n",
        "    print(\"Loading dataset paths...\")\n",
        "    test_ratio = 1.0 - Config.train_split_ratio - Config.val_split_ratio\n",
        "\n",
        "    train_files, val_files, test_files = getPathsSetsByBrand(\n",
        "        Config.dataset_root,\n",
        "        val_split=Config.val_split_ratio,\n",
        "        test_split=test_ratio,\n",
        "        min_images_per_brand=2\n",
        "    )\n",
        "\n",
        "    # Transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.5, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    if loss_type == \"triplet\":\n",
        "        print(\"Using DatasetTriplet\")\n",
        "        train_dataset = DatasetTriplet(train_files, transform=train_transform)\n",
        "        val_dataset = DatasetTriplet(val_files, transform=val_transform)\n",
        "    else:\n",
        "        print(\"Using DatasetContrastive (Pairs)\")\n",
        "        train_dataset = DatasetContrastive(train_files, transform=train_transform)\n",
        "        val_dataset = DatasetContrastive(val_files, transform=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, persistent_workers=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    # --- MODEL & LOSS ---\n",
        "    print(\"Initializing LogoResNet50...\")\n",
        "    model = LogoResNet50(embedding_dim=Config.embedding_dim, pretrained=Config.pretrained, num_of_freeze_layer=Config.freeze_layers)\n",
        "    model = model.to(device)\n",
        "\n",
        "    if loss_type == \"euclidean\":\n",
        "        criterion = ContrastiveLossEuclidean(margin=MARGIN)\n",
        "    elif loss_type == \"cosine\":\n",
        "        criterion = ContrastiveLossCosine(margin=MARGIN)\n",
        "    elif loss_type == \"triplet\":\n",
        "        criterion = TripletLoss(margin=MARGIN)\n",
        "    else:\n",
        "        raise ValueError(f\"Loss type {loss_type} not supported\")\n",
        "\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "\n",
        "    # --- SETUP CSV E HISTORY ---\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    csv_path = os.path.join(save_dir, \"training_history.csv\")\n",
        "\n",
        "\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(csv_path):\n",
        "        print(\"Existing CSV found, loading historical data for charts\")\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            train_losses = df['Train Loss'].tolist()\n",
        "            val_losses = df['Val Loss'].tolist()\n",
        "            start_epoch = len(train_losses)\n",
        "            print(f\"Resuming from epoch {start_epoch + 1}\")\n",
        "        except:\n",
        "            print(\"Error reading CSV\")\n",
        "    else:\n",
        "        with open(csv_path, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Epoch\", \"Train Loss\", \"Val Loss\"])\n",
        "\n",
        "    # Resume (if the file for the current epoch exists)\n",
        "    resume_ckpt = os.path.join(save_dir, f\"model_epoch_{start_epoch}.pth\")\n",
        "    if os.path.exists(resume_ckpt) and start_epoch > 0:\n",
        "        print(f\"Loading weights from: {resume_ckpt}\")\n",
        "        model.load_state_dict(torch.load(resume_ckpt, map_location=device))\n",
        "        print(\"Weights loaded\")\n",
        "\n",
        "    try: from tqdm import tqdm\n",
        "    except ImportError: tqdm = lambda iterator, desc=\"\": iterator\n",
        "\n",
        "    # --- TRAINING LOOP ---\n",
        "    for epoch in range(start_epoch, Config.epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.epochs}\")\n",
        "\n",
        "        for batch in pbar:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if loss_type == \"triplet\":\n",
        "                anc, pos, neg = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "                loss = criterion(model(anc), model(pos), model(neg))\n",
        "            else:\n",
        "                img1 = batch[0]['image'].to(device)\n",
        "                img2 = batch[1]['image'].to(device)\n",
        "                label = batch[2].to(device)\n",
        "\n",
        "                out1 = model(img1)\n",
        "                out2 = model(img2)\n",
        "\n",
        "\n",
        "                if loss_type == \"euclidean\":\n",
        "                    target = label.float()\n",
        "                else:\n",
        "                    target = label.float()\n",
        "                    target[target == 0] = -1\n",
        "\n",
        "                loss = criterion(out1, out2, target)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if hasattr(pbar, \"set_postfix\"): pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1} DONE. Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # --- VALIDATION ---\n",
        "        model.eval()\n",
        "        val_loss_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                if loss_type == \"triplet\":\n",
        "                    anc, pos, neg = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "                    loss = criterion(model(anc), model(pos), model(neg))\n",
        "                else:\n",
        "                    img1 = batch[0]['image'].to(device)\n",
        "                    img2 = batch[1]['image'].to(device)\n",
        "                    label = batch[2].to(device)\n",
        "                    out1, out2 = model(img1), model(img2)\n",
        "\n",
        "                    if loss_type == \"euclidean\":\n",
        "                        target = label.float()\n",
        "                    else:\n",
        "                        target = label.float(); target[target == 0] = -1\n",
        "                    loss = criterion(out1, out2, target)\n",
        "                val_loss_acc += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss_acc / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        print(f\"VALIDATION Epoch {epoch+1}: Loss = {avg_val_loss:.4f}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # SAVING\n",
        "        ckpt_path = os.path.join(save_dir, f\"model_epoch_{epoch+1}.pth\")\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "        print(f\"Checkpoint saved: {ckpt_path}\")\n",
        "\n",
        "        # UPDATING CSV E PLOT\n",
        "        with open(csv_path, mode='a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([epoch+1, avg_loss, avg_val_loss])\n",
        "        print(\"CSV updated.\")\n",
        "        save_plots(train_losses, val_losses, save_dir, title_suffix=f\"({loss_type})\")\n",
        "\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "k8TKhcyC_FsE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}